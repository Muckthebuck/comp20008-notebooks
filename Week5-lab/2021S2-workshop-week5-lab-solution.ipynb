{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements Of Data Processing (2021S1) - Week 5\n",
    "\n",
    "### Regular Expressions (Regex)\n",
    "- Regular expressions allow you to match patterns in strings, rather than matching exact characters.  \n",
    "- For example, if I wanted to find all phone numbers with form `(03) xxxx xxxx`, where `x` is some arbitrary digit, then I could use a regular expression like this: \n",
    "    - `\\(03\\) \\d\\d\\d\\d \\d\\d\\d\\d` \n",
    "    - `\\(03\\) \\d{4} \\d{4}` where `\\d{4}` matches a digit exactly 4 times\n",
    "- Here's a good tutorial on Python regex: https://www.w3schools.com/python/python_regex.asp\n",
    "- and a website to test your regex expressions with test cases: https://regex101.com/\n",
    "\n",
    "### Regex with Python\n",
    "- The `re` library in Python allows you to use regular expressions. \n",
    "- Methods of note are:\n",
    "    - `.search()` (search for a particular pattern given a string)\n",
    "    - `.findall()` (finds all substrings that match a given pattern)\n",
    "    - `.sub()` (replaces all matched substrings with another given substring)\n",
    "    \n",
    "### Regex Quantifiers\n",
    "- `?`: exactly zero or one occurrences of the preceding element\n",
    "- `*`: zero or more occurrences of the preceding element\n",
    "- `+`: one or more occurrences of the preceding element\n",
    "- `{n}`: preceding item is matched exactly `n` times\n",
    "- `{,n}`: preceding item is matched up to `n` times inclusive\n",
    "- `{n,}`: preceding item is matched at least `n` or more times\n",
    "- `{m,n}`: preceding item is matched at least `m` or more times, but up to `n` times inclusive\n",
    "    \n",
    "### Escaping Special Characters\n",
    "- Like special characters in Python (i.e `\\n`), you will also need to escape special characters in regex.\n",
    "- For example, if you wanted to match a literal bracket `(`, you have to type `\\(` to escape it as `()` in regex is used to capture a literal group of characters\n",
    "    \n",
    "Consider the phone number from the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone number found\n",
      "['(03) 9923 1123']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = r'Name: Chris, ph: (03) 9923 1123, comments: this is not my real number'\n",
    "\n",
    "# this is the regex pattern we want\n",
    "# notice that we need to \"escape\" the brackets\n",
    "pattern = r'\\(03\\) \\d{4} \\d{4}'\n",
    "\n",
    "if re.search(pattern, string) :\n",
    "    print(\"Phone number found\")\n",
    "    print(re.findall(pattern, string))\n",
    "else :\n",
    "    print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 1 </span>\n",
    "\n",
    "Modify the example above so that it will also find phone numbers starting with `(03)` that:\n",
    "- have missing brackets;\n",
    "- instead of a single space, uses hyphens, backslashes, and/or spaces.\n",
    "\n",
    "Your program should match all elements in ***strings*** in the code segment below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone number found\n",
      "['(03) 9923 1123']\n",
      "Phone number found\n",
      "['03-9923-1123']\n",
      "Phone number found\n",
      "['(03)-9923-1123']\n",
      "Phone number found\n",
      "['(03)\\\\-9923 -1123']\n"
     ]
    }
   ],
   "source": [
    "# This examples looks for phone numbers that match the format above\n",
    "import re\n",
    "\n",
    "strings = [\n",
    "    r'Name: Chris, ph: (03) 9923 1123, comments: this is not my real number',\n",
    "    r'Name: John, ph: 03-9923-1123, comments: this might be an old number',\n",
    "    r'Name: Sara, phone: (03)-9923-1123, comments: there is data quality issues, so far, three people sharig the same number',\n",
    "    r'Name: Christopher, ph: (03)\\-9923 -1123, comments, is this the same Chris in the first record?'\n",
    "]\n",
    "\n",
    "# change this line\n",
    "pattern = r'\\(?03\\)?[\\\\\\s-]+\\d{4}[\\\\\\s-]+\\d{4}'\n",
    "\n",
    "for s in strings:\n",
    "    if re.search(pattern, s) :\n",
    "        print(\"Phone number found\")\n",
    "        print(re.findall(pattern, s))\n",
    "    else :\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 2 </span>\n",
    "- Write a program that will remove **all leading zeros** from an IP address\n",
    "- For example, `0216.08.094.102` should become `216.8.94.196`\n",
    "- Your program should match all elements in `ip_addr` in the code segment below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.8.94.102\n"
     ]
    }
   ],
   "source": [
    "#Exercise 2: Write a program that will remove all leading zeros from an IP address\n",
    "#For example, 0216.08.094.102 should become 216.8.94.196\n",
    "import re\n",
    "\n",
    "ip_addr = '0216.08.094.102'\n",
    "\n",
    "#change this line\n",
    "revised_addr = ip_addr\n",
    "\n",
    "# solution\n",
    "#revised_addr = re.sub('\\.[0]*', '.', ip_addr)\n",
    "pattern = r'(^|\\.)0*'\n",
    "revised_addr = re.sub(pattern, r'\\1' , ip_addr)\n",
    "#\n",
    "\n",
    "print(revised_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity  \n",
    "\n",
    "Jaccard similarity (set-based) is a measure of calculating the similarity between two $n$-grams.\n",
    "\n",
    "Let $A$ and $B$ be two $n$-grams. Then the Jaccard similarity can be computed as:\n",
    "$$\n",
    "\\text{sim} = J(A, B) = \\frac{A\\cap B}{A\\cup B}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- The intersection is the number of common elements between the two sets;\n",
    "- and the union contains the set of all elements in the two sets.\n",
    "\n",
    "For example, if I had two sets of numbers:\n",
    "- $A = \\{0,1,2,5,6\\}, B = \\{0,2,3,4,5,7,9\\}$\n",
    "- Then $A\\cap B = \\{0, 2, 5\\}$ and $A\\cup B = \\{0, 1, 2, 3, 4, 5, 6, 7, 9\\}$\n",
    "- Therefore, $J(A, B) = 3 / 9 = 0.33$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 3 </span>\n",
    "\n",
    "1. Use nltk.util.ngram to produce bi-grams (your device may need to download the `punkt` toolbox for `nltk`).\n",
    "1. Then calculate the Jaccard similarity for each bi-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 Jaccard Similarity between sent1 and sent2 with ngram 2\n",
      "0.75 Jaccard Distance between sent1 and sent2 with ngram 2\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sent1 = \"crat\"\n",
    "sent2 = \"cart\"\n",
    "ng1_chars = set(nltk.ngrams(sent1, n=2, pad_right=True, pad_left=True))\n",
    "ng2_chars = set(nltk.ngrams(sent2, n=2, pad_right=True, pad_left=True))\n",
    "similarity=len(set (ng1_chars) .intersection (set (ng2_chars)))/len(set (ng1_chars) .union (set (ng2_chars)))\n",
    "print(similarity, \"Jaccard Similarity between sent1 and sent2 with ngram 2\")\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_chars, ng2_chars)\n",
    "print(jd_sent_1_2, \"Jaccard Distance between sent1 and sent2 with ngram 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Folding ##\n",
    "Case folding  removes all case distinctions present in a string. It is used for caseless matching, i.e. ignores cases when comparing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 4 </span>\n",
    "\n",
    "Use appropraite functions to covert string \"Whereof one cannot speak, thereof one must be silent.\" in\n",
    "\n",
    "(1) Lower case\n",
    "\n",
    "(2) Upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whereof one cannot speak, thereof one must be silent.\n",
      "WHEREOF ONE CANNOT SPEAK, THEREOF ONE MUST BE SILENT.\n"
     ]
    }
   ],
   "source": [
    "s = \"Whereof one cannot speak, thereof one must be silent.\"\n",
    "\n",
    "print(s.lower())\n",
    "\n",
    "print(s.upper())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing ##\n",
    "The ***nltk*** library provides you with tools for natural language processing, including tokenizing, stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 22\n",
      ". 10\n",
      "-- 7\n",
      "dedic 6\n",
      "nation 5\n",
      "live 4\n",
      "great 3\n",
      "It 3\n",
      "dead 3\n",
      "us 3\n",
      "shall 3\n",
      "peopl 3\n",
      "new 2\n",
      "conceiv 2\n",
      "men 2\n",
      "war 2\n",
      "long 2\n",
      "We 2\n",
      "gave 2\n",
      "consecr 2\n",
      "the 2\n",
      "far 2\n",
      "rather 2\n",
      "devot 2\n",
      "four 1\n",
      "score 1\n",
      "seven 1\n",
      "year 1\n",
      "ago 1\n",
      "father 1\n",
      "brought 1\n",
      "forth 1\n",
      "contin 1\n",
      "liberti 1\n",
      "proposit 1\n",
      "creat 1\n",
      "equal 1\n",
      "now 1\n",
      "engag 1\n",
      "civil 1\n",
      "test 1\n",
      "whether 1\n",
      "endur 1\n",
      "met 1\n",
      "battle-field 1\n",
      "come 1\n",
      "portion 1\n",
      "field 1\n",
      "final 1\n",
      "rest 1\n",
      "place 1\n",
      "might 1\n",
      "altogeth 1\n",
      "fit 1\n",
      "proper 1\n",
      "but 1\n",
      "larger 1\n",
      "sens 1\n",
      "hallow 1\n",
      "ground 1\n",
      "brave 1\n",
      "struggl 1\n",
      "poor 1\n",
      "power 1\n",
      "add 1\n",
      "detract 1\n",
      "world 1\n",
      "littl 1\n",
      "note 1\n",
      "rememb 1\n",
      "say 1\n",
      "never 1\n",
      "forget 1\n",
      "unfinish 1\n",
      "work 1\n",
      "fought 1\n",
      "thu 1\n",
      "nobli 1\n",
      "advanc 1\n",
      "task 1\n",
      "remain 1\n",
      "honor 1\n",
      "take 1\n",
      "increas 1\n",
      "caus 1\n",
      "last 1\n",
      "full 1\n",
      "measur 1\n",
      "highli 1\n",
      "resolv 1\n",
      "die 1\n",
      "vain 1\n",
      "god 1\n",
      "birth 1\n",
      "freedom 1\n",
      "govern 1\n",
      "perish 1\n",
      "earth 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "# first time:\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#\n",
    "porterStemmer = PorterStemmer()\n",
    "\n",
    "speech = 'Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal. Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this. But, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.'\n",
    "wordList = nltk.word_tokenize(speech)\n",
    "\n",
    "# run the line to download it the first time:\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "filteredList = [w for w in wordList if not w in stopWords]\n",
    "\n",
    "wordDict = {}\n",
    "for word in filteredList:\n",
    "    stemWord = porterStemmer.stem(word)\n",
    "    if stemWord in wordDict : \n",
    "        wordDict[stemWord] = wordDict[stemWord] +1\n",
    "    else :\n",
    "        wordDict[stemWord] = 1\n",
    "\n",
    "wordDict = {k: v for k, v in sorted(wordDict.items(), key=lambda item: item[1], reverse=True)}\n",
    "for key in wordDict : print(key, wordDict[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 5 </span>\n",
    "\n",
    "Modify the example above to use a WordNet Lemmatizer instead of a porter stemmer.\n",
    "\n",
    "Comment on the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 22\n",
      ". 10\n",
      "-- 7\n",
      "nation 5\n",
      "dedicated 4\n",
      "great 3\n",
      "It 3\n",
      "dead 3\n",
      "u 3\n",
      "shall 3\n",
      "people 3\n",
      "new 2\n",
      "conceived 2\n",
      "men 2\n",
      "war 2\n",
      "long 2\n",
      "We 2\n",
      "dedicate 2\n",
      "gave 2\n",
      "The 2\n",
      "living 2\n",
      "far 2\n",
      "rather 2\n",
      "devotion 2\n",
      "Four 1\n",
      "score 1\n",
      "seven 1\n",
      "year 1\n",
      "ago 1\n",
      "father 1\n",
      "brought 1\n",
      "forth 1\n",
      "continent 1\n",
      "Liberty 1\n",
      "proposition 1\n",
      "created 1\n",
      "equal 1\n",
      "Now 1\n",
      "engaged 1\n",
      "civil 1\n",
      "testing 1\n",
      "whether 1\n",
      "endure 1\n",
      "met 1\n",
      "battle-field 1\n",
      "come 1\n",
      "portion 1\n",
      "field 1\n",
      "final 1\n",
      "resting 1\n",
      "place 1\n",
      "life 1\n",
      "might 1\n",
      "live 1\n",
      "altogether 1\n",
      "fitting 1\n",
      "proper 1\n",
      "But 1\n",
      "larger 1\n",
      "sense 1\n",
      "consecrate 1\n",
      "hallow 1\n",
      "ground 1\n",
      "brave 1\n",
      "struggled 1\n",
      "consecrated 1\n",
      "poor 1\n",
      "power 1\n",
      "add 1\n",
      "detract 1\n",
      "world 1\n",
      "little 1\n",
      "note 1\n",
      "remember 1\n",
      "say 1\n",
      "never 1\n",
      "forget 1\n",
      "unfinished 1\n",
      "work 1\n",
      "fought 1\n",
      "thus 1\n",
      "nobly 1\n",
      "advanced 1\n",
      "task 1\n",
      "remaining 1\n",
      "honored 1\n",
      "take 1\n",
      "increased 1\n",
      "cause 1\n",
      "last 1\n",
      "full 1\n",
      "measure 1\n",
      "highly 1\n",
      "resolve 1\n",
      "died 1\n",
      "vain 1\n",
      "God 1\n",
      "birth 1\n",
      "freedom 1\n",
      "government 1\n",
      "perish 1\n",
      "earth 1\n"
     ]
    }
   ],
   "source": [
    "#Solution to Exercise : \n",
    "#Modify the example above to use a WordNet Lemmatizer instead of a Porter Stemmer\n",
    "#Comment on the differences\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# first time, run the line:\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "speech = 'Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal. Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this. But, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.'\n",
    "wordList = nltk.word_tokenize(speech)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "filteredList = [w for w in wordList if not w in stopWords]\n",
    "\n",
    "wordDict = {}\n",
    "for word in filteredList:\n",
    "    stemWord = lemmatizer.lemmatize(word)\n",
    "    if stemWord in wordDict : \n",
    "        wordDict[stemWord] = wordDict[stemWord] +1\n",
    "    else :\n",
    "        wordDict[stemWord] = 1\n",
    "\n",
    "wordDict = {k: v for k, v in sorted(wordDict.items(), key=lambda item: item[1], reverse=True)}\n",
    "for key in wordDict : print(key, wordDict[key])\n",
    "\n",
    "#The most obvious difference is that the lemmatizer produces actual words rather than stems.\n",
    "#Lemmatizer will also handle case differences (e.g. eat vs ate) that the Stemmer will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
